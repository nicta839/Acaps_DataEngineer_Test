{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa377d6",
   "metadata": {},
   "source": [
    "# Logistic regression using word embeddings\n",
    "\n",
    "In this notebook, we implement another model applying word embeddings for the logistic regression model.\n",
    "\n",
    "We start by installing gensim, training a word2vec model and applying this embedding for multinomial logistic regression in an attempt to improve the performance of the preivously seen models using bag-of-words vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90910321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\nicol\\anaconda3\\envs\\acaps\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\nicol\\anaconda3\\envs\\acaps\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\nicol\\anaconda3\\envs\\acaps\\lib\\site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\nicol\\anaconda3\\envs\\acaps\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\nicol\\anaconda3\\envs\\acaps\\lib\\site-packages (from gensim) (0.29.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e60a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8e74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451150f9",
   "metadata": {},
   "source": [
    "We load the undersampled and full dataset to check for increase in performance using the undersampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdca14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load back data\n",
    "df_train = pd.read_csv('../data/processed/normalized_train.csv')\n",
    "df_test = pd.read_csv('../data/processed/normalized_test.csv')\n",
    "df_under_train = pd.read_csv('../data/processed/undersampled_train.csv')\n",
    "df_under_test = pd.read_csv('../data/processed/undersampled_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e9feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed a word2vec model with the data\n",
    "w2v_model = gensim.models.Word2Vec(list(df_train['Data']), vector_size=100, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cebb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate aggregated sentence vectors based on the word vectors for each word in the sentence\n",
    "# Replace the words in each abstract with the learned word vector\n",
    "words = set(w2v_model.wv.index_to_key )\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in df_train['Data']])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in df_test['Data']])\n",
    "X_train_under = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in df_under_train['Data']])\n",
    "X_test_under = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in df_under_test['Data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481f06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the word vectors for each sentence and assign a vector of zeros if the model\n",
    "# did not learn any of the words in the text during training\n",
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_train_under_avg = []\n",
    "for v in X_train_under:\n",
    "    if v.size:\n",
    "        X_train_under_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_under_avg.append(np.zeros(100, dtype=float))\n",
    "        \n",
    "X_test_under_avg = []\n",
    "for v in X_test_under:\n",
    "    if v.size:\n",
    "        X_test_under_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_under_avg.append(np.zeros(100, dtype=float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a598e",
   "metadata": {},
   "source": [
    "We implement the logistic regression classifier using the previously seen word2vec model on both the undersampled and the full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "841fd900",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1, multi_class = 'multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d75ac1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset logistic regression model\n",
    "lr_model_full = clf.fit(X_train_vect_avg, df_train['Label'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b96b267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.86      0.64       840\n",
      "           1       0.73      0.29      0.42       353\n",
      "           2       0.66      0.66      0.66       785\n",
      "           3       0.54      0.04      0.07       376\n",
      "\n",
      "    accuracy                           0.58      2354\n",
      "   macro avg       0.61      0.46      0.45      2354\n",
      "weighted avg       0.60      0.58      0.52      2354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predict_test = lr_model_full.predict(X_test_vect_avg)\n",
    "\n",
    "# report\n",
    "print(classification_report(df_test['Label'], predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab61a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampled dataset logistic regression model\n",
    "\n",
    "lr_model_under = clf.fit(X_train_under_avg, df_under_train['Label'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6708a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.54      0.50       353\n",
      "           1       0.71      0.53      0.61       353\n",
      "           2       0.64      0.53      0.58       353\n",
      "           3       0.45      0.56      0.50       353\n",
      "\n",
      "    accuracy                           0.54      1412\n",
      "   macro avg       0.57      0.54      0.55      1412\n",
      "weighted avg       0.57      0.54      0.55      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predict_test_under = lr_model_under.predict(X_test_under_avg)\n",
    "\n",
    "# report\n",
    "print(classification_report(df_under_test['Label'], predict_test_under))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ab32b",
   "metadata": {},
   "source": [
    "The results indicate the poor representation of the words as embeddings for this problem. The architecture or the model might be maladapted to this particular case. The results are no better than a random classifier for all datasamples.\n",
    "\n",
    "We choose not to save and pursue this model due to poor performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
