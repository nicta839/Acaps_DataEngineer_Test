{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d84cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# File manipulation\n",
    "import os\n",
    "import shutil\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Time\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8145ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('../data/processed/normalized_train.csv')\n",
    "df_test = pd.read_csv('../data/processed/normalized_test.csv')\n",
    "df_under_train = pd.read_csv('../data/processed/undersampled_train.csv')\n",
    "df_under_test = pd.read_csv('../data/processed/undersampled_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4bec005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df4ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression Pipeline\n",
    "pipe_lr = Pipeline([\n",
    "    (\"countVectorizer\", CountVectorizer()),\n",
    "    (\"LogisticRegression\", LogisticRegression(multi_class=\"multinomial\", max_iter=100))])\n",
    "\n",
    "# RandomForestClassifier Pipeline\n",
    "pipe_rf = Pipeline([\n",
    "    ('countVectorizer', CountVectorizer()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier(random_state=0))])\n",
    "\n",
    "# Define pipeline parameters for all models\n",
    "params_lr = {\n",
    "    \"countVectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "    \"countVectorizer__binary\": [True, False],\n",
    "    \"LogisticRegression__C\": [0.5, 1.0]\n",
    "}\n",
    "\n",
    "params_rf = {\n",
    "    \"countVectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "    \"countVectorizer__binary\": [True, False],\n",
    "    \"RandomForestClassifier__criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "\n",
    "grid_param_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=params_lr,\n",
    "    scoring='accuracy',\n",
    "    cv=3) \n",
    "\n",
    "grid_param_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=params_rf,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3)\n",
    "\n",
    "\n",
    "pipelines = [(grid_param_lr, params_lr, pipe_lr), (grid_param_rf, params_rf, pipe_rf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc1c2cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Pipeline: ['countVectorizer', 'LogisticRegression']\n",
      "Parameters:\n",
      "{'LogisticRegression__C': [0.5, 1.0],\n",
      " 'countVectorizer__binary': [True, False],\n",
      " 'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
      "Done in 552.205s\n",
      "\n",
      "Best score: 0.869\n",
      "Best parameters set:\n",
      "\tLogisticRegression__C: 0.5\n",
      "\tcountVectorizer__binary: True\n",
      "\tcountVectorizer__ngram_range: (1, 2)\n",
      "\n",
      "Classification report for optimal parameters (training set)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3366\n",
      "           1       1.00      1.00      1.00      1570\n",
      "           2       1.00      1.00      1.00      2972\n",
      "           3       1.00      1.00      1.00      1538\n",
      "\n",
      "    accuracy                           1.00      9446\n",
      "   macro avg       1.00      1.00      1.00      9446\n",
      "weighted avg       1.00      1.00      1.00      9446\n",
      "\n",
      "\n",
      "Classification report for optimal parameters (test data)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       840\n",
      "           1       0.88      0.91      0.90       353\n",
      "           2       0.97      0.96      0.96       785\n",
      "           3       0.75      0.57      0.65       376\n",
      "\n",
      "    accuracy                           0.86      2354\n",
      "   macro avg       0.85      0.83      0.84      2354\n",
      "weighted avg       0.86      0.86      0.86      2354\n",
      "\n",
      "################################################################\n",
      "Performing grid search...\n",
      "Pipeline: ['countVectorizer', 'RandomForestClassifier']\n",
      "Parameters:\n",
      "{'RandomForestClassifier__criterion': ['gini', 'entropy'],\n",
      " 'countVectorizer__binary': [True, False],\n",
      " 'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
      "Done in 2353.477s\n",
      "\n",
      "Best score: 0.816\n",
      "Best parameters set:\n",
      "\tRandomForestClassifier__criterion: 'gini'\n",
      "\tcountVectorizer__binary: True\n",
      "\tcountVectorizer__ngram_range: (1, 1)\n",
      "\n",
      "Classification report for optimal parameters (training set)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3366\n",
      "           1       1.00      1.00      1.00      1570\n",
      "           2       1.00      1.00      1.00      2972\n",
      "           3       1.00      1.00      1.00      1538\n",
      "\n",
      "    accuracy                           1.00      9446\n",
      "   macro avg       1.00      1.00      1.00      9446\n",
      "weighted avg       1.00      1.00      1.00      9446\n",
      "\n",
      "\n",
      "Classification report for optimal parameters (test data)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81       840\n",
      "           1       0.88      0.85      0.87       353\n",
      "           2       0.96      0.95      0.96       785\n",
      "           3       0.88      0.21      0.34       376\n",
      "\n",
      "    accuracy                           0.82      2354\n",
      "   macro avg       0.86      0.74      0.74      2354\n",
      "weighted avg       0.84      0.82      0.79      2354\n",
      "\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for pipe in pipelines:\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"Pipeline:\", [name for name, _ in pipe[2].steps])\n",
    "    print(\"Parameters:\")\n",
    "    pprint(pipe[1])\n",
    "    t0 = time()\n",
    "    pipe[0].fit(df_train[\"Data\"], df_train[\"Label\"])\n",
    "    print(\"Done in %0.3fs\\n\" % (time() - t0))\n",
    "    print(\"Best score: %0.3f\" % pipe[0].best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = pipe[0].best_estimator_.get_params()\n",
    "    \n",
    "    \n",
    "    for param_name in sorted(pipe[1].keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    # On training data\n",
    "    predict_train = pipe[0].best_estimator_.predict(df_train[\"Data\"])\n",
    "    # On test data\n",
    "    predict_test = pipe[0].best_estimator_.predict(df_test[\"Data\"])\n",
    "\n",
    "    # classification report for optimal parameters (training set)\n",
    "    print(\"\\nClassification report for optimal parameters (training set)\\n\")\n",
    "    print(classification_report(df_train[\"Label\"], predict_train))\n",
    "\n",
    "    # classification report for optimal parameters (test set)\n",
    "    print(\"\\nClassification report for optimal parameters (test data)\\n\")\n",
    "    print(classification_report(df_test[\"Label\"], predict_test))\n",
    "    \n",
    "    print(\"################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5173734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Pipeline: ['countVectorizer', 'LogisticRegression']\n",
      "Parameters:\n",
      "{'LogisticRegression__C': [0.5, 1.0],\n",
      " 'countVectorizer__binary': [True, False],\n",
      " 'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
      "Done in 322.999s\n",
      "\n",
      "Best score: 0.847\n",
      "Best parameters set:\n",
      "\tLogisticRegression__C: 0.5\n",
      "\tcountVectorizer__binary: True\n",
      "\tcountVectorizer__ngram_range: (1, 2)\n",
      "\n",
      "Classification report for optimal parameters (training set)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1538\n",
      "           1       1.00      1.00      1.00      1538\n",
      "           2       1.00      1.00      1.00      1538\n",
      "           3       1.00      1.00      1.00      1538\n",
      "\n",
      "    accuracy                           1.00      6152\n",
      "   macro avg       1.00      1.00      1.00      6152\n",
      "weighted avg       1.00      1.00      1.00      6152\n",
      "\n",
      "\n",
      "Classification report for optimal parameters (test data)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81       840\n",
      "           1       0.80      0.92      0.86       353\n",
      "           2       0.97      0.94      0.95       785\n",
      "           3       0.64      0.73      0.68       376\n",
      "\n",
      "    accuracy                           0.84      2354\n",
      "   macro avg       0.81      0.84      0.82      2354\n",
      "weighted avg       0.85      0.84      0.84      2354\n",
      "\n",
      "################################################################\n",
      "Performing grid search...\n",
      "Pipeline: ['countVectorizer', 'RandomForestClassifier']\n",
      "Parameters:\n",
      "{'RandomForestClassifier__criterion': ['gini', 'entropy'],\n",
      " 'countVectorizer__binary': [True, False],\n",
      " 'countVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
      "Done in 1217.872s\n",
      "\n",
      "Best score: 0.818\n",
      "Best parameters set:\n",
      "\tRandomForestClassifier__criterion: 'gini'\n",
      "\tcountVectorizer__binary: False\n",
      "\tcountVectorizer__ngram_range: (1, 1)\n",
      "\n",
      "Classification report for optimal parameters (training set)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1538\n",
      "           1       1.00      1.00      1.00      1538\n",
      "           2       1.00      1.00      1.00      1538\n",
      "           3       1.00      1.00      1.00      1538\n",
      "\n",
      "    accuracy                           1.00      6152\n",
      "   macro avg       1.00      1.00      1.00      6152\n",
      "weighted avg       1.00      1.00      1.00      6152\n",
      "\n",
      "\n",
      "Classification report for optimal parameters (test data)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78       840\n",
      "           1       0.77      0.90      0.83       353\n",
      "           2       0.97      0.91      0.94       785\n",
      "           3       0.58      0.72      0.64       376\n",
      "\n",
      "    accuracy                           0.81      2354\n",
      "   macro avg       0.79      0.82      0.80      2354\n",
      "weighted avg       0.83      0.81      0.82      2354\n",
      "\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "#### UNDERSAMPLED DATA COUNT VECTORIZER####\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for pipe in pipelines:\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"Pipeline:\", [name for name, _ in pipe[2].steps])\n",
    "    print(\"Parameters:\")\n",
    "    pprint(pipe[1])\n",
    "    t0 = time()\n",
    "    pipe[0].fit(df_under_train[\"Data\"], df_under_train[\"Label\"])\n",
    "    print(\"Done in %0.3fs\\n\" % (time() - t0))\n",
    "    print(\"Best score: %0.3f\" % pipe[0].best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = pipe[0].best_estimator_.get_params()\n",
    "    for param_name in sorted(pipe[1].keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    # On training data\n",
    "    predict_train = pipe[0].best_estimator_.predict(df_under_train[\"Data\"])\n",
    "    # On test data\n",
    "    predict_test = pipe[0].best_estimator_.predict(df_test[\"Data\"])\n",
    "\n",
    "    # classification report for optimal parameters (training set)\n",
    "    print(\"\\nClassification report for optimal parameters (training set)\\n\")\n",
    "    print(classification_report(df_under_train[\"Label\"], predict_train))\n",
    "\n",
    "    # classification report for optimal parameters (test set)\n",
    "    print(\"\\nClassification report for optimal parameters (test data)\\n\")\n",
    "    print(classification_report(df_test[\"Label\"], predict_test))\n",
    "    \n",
    "    print(\"################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3644959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf vectorizer\n",
    "\n",
    "# LogisticRegression Pipeline\n",
    "pipe_lr = Pipeline([\n",
    "    (\"tfidfVectorizer\", TfidfVectorizer()),\n",
    "    (\"LogisticRegression\", LogisticRegression(multi_class=\"multinomial\", max_iter=100))])\n",
    "\n",
    "# RandomForestClassifier Pipeline\n",
    "pipe_rf = Pipeline([\n",
    "    ('tfidfVectorizer', TfidfVectorizer()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier(random_state=0))])\n",
    "\n",
    "# Define pipeline parameters for all models\n",
    "params_lr = {\n",
    "    \"tfidfVectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidfVectorizer__binary\": [True, False],\n",
    "    \"LogisticRegression__C\": [0.5, 1.0]\n",
    "}\n",
    "\n",
    "params_rf = {\n",
    "    \"tfidfVectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidfVectorizer__binary\": [True, False],\n",
    "    \"RandomForestClassifier__criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "\n",
    "grid_param_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=params_lr,\n",
    "    scoring='accuracy',\n",
    "    cv=3) \n",
    "\n",
    "grid_param_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=params_rf,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3)\n",
    "\n",
    "\n",
    "pipelines = [(grid_param_lr, params_lr, pipe_lr), (grid_param_rf, params_rf, pipe_rf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf54983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Pipeline: ['tfidfVectorizer', 'LogisticRegression']\n",
      "Parameters:\n",
      "{'LogisticRegression__C': [0.5, 1.0],\n",
      " 'tfidfVectorizer__binary': [True, False],\n",
      " 'tfidfVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
      "Done in 342.218s\n",
      "\n",
      "Best score: 0.877\n",
      "Best parameters set:\n",
      "\tLogisticRegression__C: 1.0\n",
      "\ttfidfVectorizer__binary: True\n",
      "\ttfidfVectorizer__ngram_range: (1, 1)\n",
      "\n",
      "Classification report for optimal parameters (training set)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3366\n",
      "           1       0.97      0.94      0.96      1570\n",
      "           2       0.99      0.99      0.99      2972\n",
      "           3       0.94      0.80      0.87      1538\n",
      "\n",
      "    accuracy                           0.95      9446\n",
      "   macro avg       0.95      0.93      0.94      9446\n",
      "weighted avg       0.95      0.95      0.95      9446\n",
      "\n",
      "\n",
      "Classification report for optimal parameters (test data)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       840\n",
      "           1       0.93      0.89      0.91       353\n",
      "           2       0.96      0.97      0.97       785\n",
      "           3       0.75      0.57      0.65       376\n",
      "\n",
      "    accuracy                           0.87      2354\n",
      "   macro avg       0.86      0.83      0.84      2354\n",
      "weighted avg       0.87      0.87      0.86      2354\n",
      "\n",
      "################################################################\n",
      "Performing grid search...\n",
      "Pipeline: ['tfidfVectorizer', 'RandomForestClassifier']\n",
      "Parameters:\n",
      "{'RandomForestClassifier__criterion': ['gini', 'entropy'],\n",
      " 'tfidfVectorizer__binary': [True, False],\n",
      " 'tfidfVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
      "Done in 2326.839s\n",
      "\n",
      "Best score: 0.818\n",
      "Best parameters set:\n",
      "\tRandomForestClassifier__criterion: 'gini'\n",
      "\ttfidfVectorizer__binary: False\n",
      "\ttfidfVectorizer__ngram_range: (1, 1)\n",
      "\n",
      "Classification report for optimal parameters (training set)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3366\n",
      "           1       1.00      1.00      1.00      1570\n",
      "           2       1.00      1.00      1.00      2972\n",
      "           3       1.00      1.00      1.00      1538\n",
      "\n",
      "    accuracy                           1.00      9446\n",
      "   macro avg       1.00      1.00      1.00      9446\n",
      "weighted avg       1.00      1.00      1.00      9446\n",
      "\n",
      "\n",
      "Classification report for optimal parameters (test data)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81       840\n",
      "           1       0.89      0.88      0.88       353\n",
      "           2       0.97      0.94      0.96       785\n",
      "           3       0.84      0.22      0.35       376\n",
      "\n",
      "    accuracy                           0.82      2354\n",
      "   macro avg       0.85      0.75      0.75      2354\n",
      "weighted avg       0.84      0.82      0.80      2354\n",
      "\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for pipe in pipelines:\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"Pipeline:\", [name for name, _ in pipe[2].steps])\n",
    "    print(\"Parameters:\")\n",
    "    pprint(pipe[1])\n",
    "    t0 = time()\n",
    "    pipe[0].fit(df_train[\"Data\"], df_train[\"Label\"])\n",
    "    print(\"Done in %0.3fs\\n\" % (time() - t0))\n",
    "    print(\"Best score: %0.3f\" % pipe[0].best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = pipe[0].best_estimator_.get_params()\n",
    "    for param_name in sorted(pipe[1].keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    # On training data\n",
    "    predict_train = pipe[0].best_estimator_.predict(df_train[\"Data\"])\n",
    "    # On test data\n",
    "    predict_test = pipe[0].best_estimator_.predict(df_test[\"Data\"])\n",
    "\n",
    "    # classification report for optimal parameters (training set)\n",
    "    print(\"\\nClassification report for optimal parameters (training set)\\n\")\n",
    "    print(classification_report(df_train[\"Label\"], predict_train))\n",
    "\n",
    "    # classification report for optimal parameters (test set)\n",
    "    print(\"\\nClassification report for optimal parameters (test data)\\n\")\n",
    "    print(classification_report(df_test[\"Label\"], predict_test))\n",
    "    \n",
    "    print(\"################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b030c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Pipeline: ['tfidfVectorizer', 'LogisticRegression']\n",
      "Parameters:\n",
      "{'LogisticRegression__C': [0.5, 1.0],\n",
      " 'tfidfVectorizer__binary': [True, False],\n",
      " 'tfidfVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
      "Done in 194.985s\n",
      "\n",
      "Best score: 0.858\n",
      "Best parameters set:\n",
      "\tLogisticRegression__C: 1.0\n",
      "\ttfidfVectorizer__binary: True\n",
      "\ttfidfVectorizer__ngram_range: (1, 1)\n",
      "\n",
      "Classification report for optimal parameters (training set)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1538\n",
      "           1       0.97      0.97      0.97      1538\n",
      "           2       0.99      0.99      0.99      1538\n",
      "           3       0.93      0.92      0.93      1538\n",
      "\n",
      "    accuracy                           0.95      6152\n",
      "   macro avg       0.95      0.95      0.95      6152\n",
      "weighted avg       0.95      0.95      0.95      6152\n",
      "\n",
      "\n",
      "Classification report for optimal parameters (test data)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83       840\n",
      "           1       0.86      0.92      0.89       353\n",
      "           2       0.98      0.95      0.96       785\n",
      "           3       0.64      0.74      0.69       376\n",
      "\n",
      "    accuracy                           0.86      2354\n",
      "   macro avg       0.83      0.85      0.84      2354\n",
      "weighted avg       0.86      0.86      0.86      2354\n",
      "\n",
      "################################################################\n",
      "Performing grid search...\n",
      "Pipeline: ['tfidfVectorizer', 'RandomForestClassifier']\n",
      "Parameters:\n",
      "{'RandomForestClassifier__criterion': ['gini', 'entropy'],\n",
      " 'tfidfVectorizer__binary': [True, False],\n",
      " 'tfidfVectorizer__ngram_range': [(1, 1), (1, 2)]}\n",
      "Done in 1241.658s\n",
      "\n",
      "Best score: 0.819\n",
      "Best parameters set:\n",
      "\tRandomForestClassifier__criterion: 'gini'\n",
      "\ttfidfVectorizer__binary: False\n",
      "\ttfidfVectorizer__ngram_range: (1, 1)\n",
      "\n",
      "Classification report for optimal parameters (training set)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1538\n",
      "           1       1.00      1.00      1.00      1538\n",
      "           2       1.00      1.00      1.00      1538\n",
      "           3       1.00      1.00      1.00      1538\n",
      "\n",
      "    accuracy                           1.00      6152\n",
      "   macro avg       1.00      1.00      1.00      6152\n",
      "weighted avg       1.00      1.00      1.00      6152\n",
      "\n",
      "\n",
      "Classification report for optimal parameters (test data)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79       840\n",
      "           1       0.79      0.92      0.85       353\n",
      "           2       0.97      0.91      0.94       785\n",
      "           3       0.58      0.69      0.63       376\n",
      "\n",
      "    accuracy                           0.82      2354\n",
      "   macro avg       0.79      0.82      0.80      2354\n",
      "weighted avg       0.83      0.82      0.82      2354\n",
      "\n",
      "################################################################\n"
     ]
    }
   ],
   "source": [
    "##### UNDERSAMPLED TFIDF VECTORIZER ############\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for pipe in pipelines:\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"Pipeline:\", [name for name, _ in pipe[2].steps])\n",
    "    print(\"Parameters:\")\n",
    "    pprint(pipe[1])\n",
    "    t0 = time()\n",
    "    pipe[0].fit(df_under_train[\"Data\"], df_under_train[\"Label\"])\n",
    "    print(\"Done in %0.3fs\\n\" % (time() - t0))\n",
    "    print(\"Best score: %0.3f\" % pipe[0].best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = pipe[0].best_estimator_.get_params()\n",
    "    for param_name in sorted(pipe[1].keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    # On training data\n",
    "    predict_train = pipe[0].best_estimator_.predict(df_under_train[\"Data\"])\n",
    "    # On test data\n",
    "    predict_test = pipe[0].best_estimator_.predict(df_test[\"Data\"])\n",
    "\n",
    "    # classification report for optimal parameters (training set)\n",
    "    print(\"\\nClassification report for optimal parameters (training set)\\n\")\n",
    "    print(classification_report(df_under_train[\"Label\"], predict_train))\n",
    "\n",
    "    # classification report for optimal parameters (test set)\n",
    "    print(\"\\nClassification report for optimal parameters (test data)\\n\")\n",
    "    print(classification_report(df_test[\"Label\"], predict_test))\n",
    "    \n",
    "    print(\"################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe66fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # save the model to disk\n",
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# # loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3a8caba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 171.068s\n",
      "\n",
      "Saving model...\n",
      "Model saved...\n"
     ]
    }
   ],
   "source": [
    "# Run model with best parameters\n",
    "\n",
    "# LogisticRegression Pipeline\n",
    "pipe_best = Pipeline([\n",
    "    (\"tfidfVectorizer\", TfidfVectorizer()),\n",
    "    (\"LogisticRegression\", LogisticRegression(multi_class=\"multinomial\", max_iter=100))])\n",
    "\n",
    "params_best = {\n",
    "    \"tfidfVectorizer__ngram_range\": [(1,1)],\n",
    "    \"tfidfVectorizer__binary\": [True],\n",
    "    \"LogisticRegression__C\": [1.0]\n",
    "}\n",
    "\n",
    "\n",
    "grid_param_best = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=params_lr,\n",
    "    scoring='accuracy',\n",
    "    cv=3)\n",
    "\n",
    "\n",
    "pipelines = [(grid_param_best, params_best, pipe_best)]\n",
    "t0 = time()\n",
    "model_best = pipelines[0][0].fit(df_under_train[\"Data\"], df_under_train[\"Label\"])\n",
    "print(\"Done in %0.3fs\\n\" % (time() - t0))\n",
    "\n",
    "print(\"Saving model...\")\n",
    "# save the model to disk\n",
    "with open('../models/best_model.sav', 'wb') as f:\n",
    "    pickle.dump(model_best, f)\n",
    "    \n",
    "print(\"Model saved...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
